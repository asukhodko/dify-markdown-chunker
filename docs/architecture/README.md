# ðŸ—ï¸ ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Stage 1

## ðŸ“‹ ÐžÐ±Ð·Ð¾Ñ€

Stage 1 Ð¿Ð¾ÑÑ‚Ñ€Ð¾ÐµÐ½ Ð¿Ð¾ Ð¼Ð¾Ð´ÑƒÐ»ÑŒÐ½Ð¾Ð¹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ðµ Ñ Ñ‡ÐµÑ‚ÐºÐ¸Ð¼ Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð¸ÐµÐ¼ Ð¾Ñ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ð¾ÑÑ‚Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð°Ð¼Ð¸.

## ðŸŽ¯ ÐŸÑ€Ð¸Ð½Ñ†Ð¸Ð¿Ñ‹ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹

1. **ÐœÐ¾Ð´ÑƒÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ** - ÐšÐ°Ð¶Ð´Ñ‹Ð¹ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚ Ñ€ÐµÑˆÐ°ÐµÑ‚ Ð¾Ð´Ð½Ñƒ Ð·Ð°Ð´Ð°Ñ‡Ñƒ
2. **Ð£Ð½Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ** - Ð•Ð´Ð¸Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐº Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°
3. **Ð Ð°ÑÑˆÐ¸Ñ€ÑÐµÐ¼Ð¾ÑÑ‚ÑŒ** - Ð›ÐµÐ³ÐºÐ¾ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð½Ð¾Ð²Ñ‹Ðµ Ð¿Ð°Ñ€ÑÐµÑ€Ñ‹ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ñ‹
4. **ÐÐ°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ** - ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº Ð½Ð° Ð²ÑÐµÑ… ÑƒÑ€Ð¾Ð²Ð½ÑÑ…
5. **ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ** - ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð²

## ðŸ›ï¸ Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð° ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð¾Ð²

```
stage1/
â”œâ”€â”€ types.py              # Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ðµ Ñ‚Ð¸Ð¿Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…
â”œâ”€â”€ config.py             # Ð¡Ð¸ÑÑ‚ÐµÐ¼Ð° ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ð¸
â”œâ”€â”€ errors.py             # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº
â”œâ”€â”€ 
â”œâ”€â”€ markdown_ast.py       # ÐŸÐ°Ñ€ÑÐ¸Ð½Ð³ Ð² AST
â”œâ”€â”€ fenced_block_extractor.py  # Ð˜Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð±Ð»Ð¾ÐºÐ¾Ð²
â”œâ”€â”€ element_detector.py   # ÐžÐ±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²
â”œâ”€â”€ content_analyzer.py   # ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚Ð°
â”œâ”€â”€ 
â”œâ”€â”€ interface.py          # Ð“Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ
â”œâ”€â”€ benchmark.py          # Ð‘ÐµÐ½Ñ‡Ð¼Ð°Ñ€ÐºÐ¸ Ð¿Ð°Ñ€ÑÐµÑ€Ð¾Ð²
â””â”€â”€ __init__.py          # ÐŸÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ API
```

## ðŸ”„ ÐŸÐ¾Ñ‚Ð¾Ðº Ð´Ð°Ð½Ð½Ñ‹Ñ…

```mermaid
graph TD
    A[Markdown Text] --> B[Stage1Interface]
    B --> C[MarkdownParser]
    B --> D[FencedBlockExtractor]
    B --> E[ElementDetector]
    B --> F[ContentAnalyzer]
    
    C --> G[MarkdownNode AST]
    D --> H[List[FencedBlock]]
    E --> I[ElementCollection]
    F --> J[ContentAnalysis]
    
    G --> K[Stage1Results]
    H --> K
    I --> K
    J --> K
    
    K --> L[Stage 2 Input]
```

## ðŸ§© Ð¡Ð»Ð¾Ð¸ Ð°Ñ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ñ‹

### 1. ðŸ“Š Ð¡Ð»Ð¾Ð¹ Ð´Ð°Ð½Ð½Ñ‹Ñ… (types.py)
ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ð²ÑÐµ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ðµ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð´Ð°Ð½Ð½Ñ‹Ñ…:
- `Position` - Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð² Ñ‚ÐµÐºÑÑ‚Ðµ
- `MarkdownNode` - ÑƒÐ·Ð»Ñ‹ AST
- `FencedBlock` - Ð¾Ð³Ñ€Ð°Ð¶Ð´ÐµÐ½Ð½Ñ‹Ðµ Ð±Ð»Ð¾ÐºÐ¸
- `Header`, `MarkdownList`, `Table` - ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ‹Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹
- `ContentAnalysis` - Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°

### 2. ðŸ”§ Ð¡Ð»Ð¾Ð¹ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°
ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Markdown:
- `MarkdownParser` - Ð°Ð±ÑÑ‚Ñ€Ð°ÐºÑ‚Ð½Ñ‹Ð¹ Ð¿Ð°Ñ€ÑÐµÑ€
- `MarkdownItPyAdapter` - Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€ Ð´Ð»Ñ markdown-it-py
- `MistuneAdapter` - Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€ Ð´Ð»Ñ mistune
- `CommonMarkAdapter` - Ð°Ð´Ð°Ð¿Ñ‚ÐµÑ€ Ð´Ð»Ñ commonmark

### 3. ðŸ” Ð¡Ð»Ð¾Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸:
- `FencedBlockExtractor` - Ð¸Ð·Ð²Ð»ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð±Ð»Ð¾ÐºÐ¾Ð² ÐºÐ¾Ð´Ð°
- `ElementDetector` - Ð¿Ð¾Ð¸ÑÐº ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð½Ñ‹Ñ… ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²
- `ContentAnalyzer` - Ð°Ð½Ð°Ð»Ð¸Ð· Ð¸ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸

### 4. ðŸŽ›ï¸ Ð¡Ð»Ð¾Ð¹ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ
ÐšÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ†Ð¸Ð¸:
- `Stage1Interface` - Ð³Ð»Ð°Ð²Ð½Ñ‹Ð¹ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ
- `Stage1Config` - ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ
- `ErrorCollector` - ÑÐ±Ð¾Ñ€ Ð¾ÑˆÐ¸Ð±Ð¾Ðº

### 5. ðŸŒ ÐŸÑƒÐ±Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ API
Ð£Ð´Ð¾Ð±Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð´Ð»Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¹:
- `process_markdown()` - Ð¿Ð¾Ð»Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°
- `analyze_markdown()` - Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð°Ð½Ð°Ð»Ð¸Ð·
- `parse_to_ast()` - Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³

## ðŸ”Œ Ð¢Ð¾Ñ‡ÐºÐ¸ Ñ€Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð¸Ñ

### Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð¿Ð°Ñ€ÑÐµÑ€Ð°
```python
class MyCustomAdapter(MarkdownParser):
    def parse(self, text: str) -> MarkdownNode:
        # Ð ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°
        pass
    
    def supports_positions(self) -> bool:
        return True
```

### Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð½Ð¾Ð²Ð¾Ð³Ð¾ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°
```python
class MyAnalyzer:
    def analyze(self, ast: MarkdownNode) -> MyAnalysisResult:
        # Ð ÐµÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð°
        pass
```

## âš¡ ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸

1. **Ð›ÐµÐ½Ð¸Ð²Ð°Ñ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ** - ÐŸÐ°Ñ€ÑÐµÑ€Ñ‹ ÑÐ¾Ð·Ð´Ð°ÑŽÑ‚ÑÑ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ñ€Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸
2. **ÐšÐµÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ** - Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð° ÐºÐµÑˆÐ¸Ñ€ÑƒÑŽÑ‚ÑÑ
3. **ÐŸÐ¾Ñ‚Ð¾ÐºÐ¾Ð²Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°** - Ð‘Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¾Ð±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÑŽÑ‚ÑÑ Ð¿Ð¾ Ñ‡Ð°ÑÑ‚ÑÐ¼
4. **ÐŸÑƒÐ»Ñ‹ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²** - ÐŸÐµÑ€ÐµÐ¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ñ‚ÑÐ¶ÐµÐ»Ñ‹Ñ… Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²

## ðŸ›¡ï¸ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾ÑˆÐ¸Ð±Ð¾Ðº

ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Ð¿Ñ€ÐµÐ´ÑƒÑÐ¼Ð°Ñ‚Ñ€Ð¸Ð²Ð°ÐµÑ‚ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ ÑƒÑ€Ð¾Ð²Ð½ÐµÐ¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð¾ÑˆÐ¸Ð±Ð¾Ðº:

1. **Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð¿Ð°Ñ€ÑÐµÑ€Ð°** - Fallback Ð½Ð° Ð´Ñ€ÑƒÐ³Ð¸Ðµ Ð¿Ð°Ñ€ÑÐµÑ€Ñ‹
2. **Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ ÐºÐ¾Ð¼Ð¿Ð¾Ð½ÐµÐ½Ñ‚Ð°** - Graceful degradation
3. **Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹ÑÐ°** - Ð¡Ð±Ð¾Ñ€ Ð¸ Ð°Ð³Ñ€ÐµÐ³Ð°Ñ†Ð¸Ñ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
4. **Ð£Ñ€Ð¾Ð²ÐµÐ½ÑŒ API** - ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒÑÐºÐ¸Ðµ Ð¸ÑÐºÐ»ÑŽÑ‡ÐµÐ½Ð¸Ñ

## ðŸ“ˆ ÐœÐµÑ‚Ñ€Ð¸ÐºÐ¸ Ð¸ Ð¼Ð¾Ð½Ð¸Ñ‚Ð¾Ñ€Ð¸Ð½Ð³

Ð’ÑÑ‚Ñ€Ð¾ÐµÐ½Ð½Ð°Ñ ÑÐ¸ÑÑ‚ÐµÐ¼Ð° Ð¼ÐµÑ‚Ñ€Ð¸Ðº Ð¾Ñ‚ÑÐ»ÐµÐ¶Ð¸Ð²Ð°ÐµÑ‚:
- Ð’Ñ€ÐµÐ¼Ñ Ð¿Ð°Ñ€ÑÐ¸Ð½Ð³Ð°
- ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ð½Ñ‹Ñ… ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²
- ÐžÑˆÐ¸Ð±ÐºÐ¸ Ð¸ Ð¸Ñ… Ñ‚Ð¸Ð¿Ñ‹
- Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¼ÑÑ‚Ð¸
- ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ð°Ñ€ÑÐµÑ€Ð¾Ð²

## ðŸ”® ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ðº Stage 2

ÐÑ€Ñ…Ð¸Ñ‚ÐµÐºÑ‚ÑƒÑ€Ð° Stage 1 ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ ÑÐ¿Ñ€Ð¾ÐµÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð° Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸ Ñ Stage 2:

1. **Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð²Ñ‹Ñ…Ð¾Ð´Ñ‹** - Ð’ÑÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð² ÐµÐ´Ð¸Ð½Ð¾Ð¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ
2. **Ð‘Ð¾Ð³Ð°Ñ‚Ñ‹Ðµ Ð¼ÐµÑ‚Ð°Ð´Ð°Ð½Ð½Ñ‹Ðµ** - ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ð¸, Ñ‚Ð¸Ð¿Ñ‹, ÑÐ²ÑÐ·Ð¸ Ð¼ÐµÐ¶Ð´Ñƒ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°Ð¼Ð¸
3. **Ð“Ð¸Ð±ÐºÐ°Ñ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ** - ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð¿Ð¾Ð´ Ñ€Ð°Ð·Ð½Ñ‹Ðµ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ð¸Ð¸ Ñ‡Ð°Ð½ÐºÐ¾Ð²Ð°Ð½Ð¸Ñ
4. **ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ** - ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð±Ð¾Ð»ÑŒÑˆÐ¸Ñ… ÐºÐ¾Ñ€Ð¿ÑƒÑÐ¾Ð²

---

## ðŸŒŠ Streaming Processing Architecture

### Overview

Streaming Processing enables memory-efficient chunking of large Markdown files (>10MB) through a parallel processing path that operates independently from the batch pipeline.

### Architectural Approach

**Parallel Processing Paths:**
```
Batch Path:    File â†’ Load Full â†’ Parse â†’ Chunk â†’ Output
Streaming Path: File â†’ Buffer â†’ Parse Window â†’ Chunk Window â†’ Output
```

**Design Rationale:**
1. **Preservation:** Maintains existing batch pipeline performance
2. **Isolation:** Streaming complexity isolated in dedicated module
3. **Backward Compatibility:** No impact on existing API contracts
4. **Opt-in Usage:** Users explicitly choose streaming via `chunk_file_streaming()`

### Component Structure

```
markdown_chunker_v2/streaming/
â”œâ”€â”€ __init__.py          # Public exports
â”œâ”€â”€ config.py            # StreamingConfig
â”œâ”€â”€ buffer_manager.py    # BufferManager class
â”œâ”€â”€ fence_tracker.py     # FenceTracker class
â”œâ”€â”€ split_detector.py    # Safe split detection logic
â””â”€â”€ streaming_chunker.py # Main StreamingChunker class
```

### Data Flow

```mermaid
graph TB
    A[Large File] --> B[BufferManager]
    B --> C[Read 100KB Window]
    C --> D[SplitDetector]
    D --> E{Safe Boundary?}
    E -->|Yes| F[Parse Window]
    E -->|No| G[Extend Buffer]
    G --> C
    F --> H[Apply Strategy]
    H --> I[Yield Chunks]
    I --> J{More Data?}
    J -->|Yes| C
    J -->|No| K[Complete]
```

### Safe Split Detection

**Priority Order:**
1. Line before `#` header (highest priority)
2. Double newline `\n\n` (paragraph boundary)
3. Single newline outside code fence
4. Fallback: 80% of buffer (hard split)

**Fence Tracking:** `FenceTracker` maintains state to prevent splitting code blocks:
```python
class FenceTracker:
    def track_line(line: str) -> None
    def is_inside_fence() -> bool
    def get_fence_info() -> Optional[Tuple[str, int]]
    def reset() -> None
```

### Memory Management

**Memory Bounds:**
```
Peak Memory = buffer_size + overlap_size + processing_overhead
            â‰ˆ 100KB + 20 lines + ~50KB
            â‰ˆ 150KB per window
```

**Guarantees:**
- Memory usage <50MB for ANY file size
- Configurable `max_memory_mb` enforces ceiling
- Explicit buffer clearing after each window

### Strategy Compatibility

| Strategy | Window Compatibility | Notes |
|----------|---------------------|-------|
| CodeAwareStrategy | Full | Code blocks atomic within windows |
| StructuralStrategy | Full | Headers preserved at boundaries |
| FallbackStrategy | Full | Paragraph-based; natural fit |
| ListAwareStrategy | Partial | May split complex nested lists |

**Strategy Selection:** Preview analysis reads first 100KB to select global strategy, ensuring consistency across windows.

### Performance Characteristics

**Processing Speed:**
- 10MB file: ~500ms
- 100MB file: ~5s
- Throughput: >10MB/second

**Memory Usage:**
- Constant regardless of file size
- Peak: ~15MB for any document
- Overhead: ~10-15% vs batch

### Integration Points

**Public API in MarkdownChunker:**
```python
def chunk_file_streaming(
    self,
    file_path: str,
    streaming_config: Optional[StreamingConfig] = None
) -> Iterator[Chunk]

def chunk_stream(
    self,
    stream: io.TextIOBase,
    streaming_config: Optional[StreamingConfig] = None
) -> Iterator[Chunk]
```

**Metadata Enrichment:**
Streaming chunks include:
- `stream_window_index`: Which buffer produced chunk
- `stream_chunk_index`: Global chunk counter
- `is_cross_window`: Spans boundary flag
- All standard metadata preserved

### Quality Guarantees

**Atomic Block Preservation:**
- Code blocks never split mid-block
- Tables never split mid-table  
- LaTeX formulas preserved complete
- Headers maintained at boundaries

**Testing:**
- Property-based tests for invariants
- Memory profiling with tracemalloc
- Batch equivalence validation
- Large file corpus (101KB, 80KB, 72KB files)

### Future Enhancements

**Out of Scope (Current Version):**
1. Async streaming (`async for` pattern)
2. Parallel window processing
3. Smart preview analysis (first 1MB)
4. Compressed stream support (`.md.gz`)
5. Streaming hierarchical chunking

**Recommendation:** Implement basic streaming first, add enhancements based on usage patterns.

---

## See Also

- [Streaming API Reference](../api/streaming.md)
- [Chunker Architecture](chunker.md)
- [Performance Guide](../guides/performance.md)