# –¶–µ–ª–µ–≤–∞—è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞: –°—Ç—Ä–∞—Ç–µ–≥–∏—è –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è

## –û–±–∑–æ—Ä

–ü–µ—Ä–µ—Ö–æ–¥ –æ—Ç 1853 —Ç–µ—Å—Ç–æ–≤ (~45K —Å—Ç—Ä–æ–∫) –∫ ~50 —Ç–µ—Å—Ç–∞–º (~2K —Å—Ç—Ä–æ–∫).

**–ü—Ä–∏–Ω—Ü–∏–ø:** –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ß–¢–û —Å–∏—Å—Ç–µ–º–∞ –¥–µ–ª–∞–µ—Ç (–¥–æ–º–µ–Ω–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞), –∞ –Ω–µ –ö–ê–ö –æ–Ω–∞ —ç—Ç–æ –¥–µ–ª–∞–µ—Ç (—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é).

## –¶–µ–ª–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

| –ú–µ—Ç—Ä–∏–∫–∞ | –¢–µ–∫—É—â–µ–µ | –¶–µ–ª–µ–≤–æ–µ | –ò–∑–º–µ–Ω–µ–Ω–∏–µ |
|---------|---------|---------|-----------|
| –¢–µ—Å—Ç–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤ | 162 | ~10 | -94% |
| –¢–µ—Å—Ç–æ–≤ | 1853 | ~50 | -97% |
| –°—Ç—Ä–æ–∫ —Ç–µ—Å—Ç–æ–≤ | ~45,600 | ~2,000 | -96% |
| –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–µ—Å—Ç—ã/–∫–æ–¥ | 1.9x | 0.4x | -79% |

## –°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–µ—Å—Ç–æ–≤

```
tests/
‚îú‚îÄ‚îÄ conftest.py              # –û–±—â–∏–µ —Ñ–∏–∫—Å—Ç—É—Ä—ã
‚îú‚îÄ‚îÄ test_properties.py       # 10 property-based —Ç–µ—Å—Ç–æ–≤ (–¥–æ–º–µ–Ω–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞)
‚îú‚îÄ‚îÄ test_design_fixes.py     # 6 property-based —Ç–µ—Å—Ç–æ–≤ (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –¥–∏–∑–∞–π–Ω–∞)
‚îú‚îÄ‚îÄ test_integration.py      # 1 –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç (full pipeline)
‚îú‚îÄ‚îÄ test_edge_cases.py       # ~10 —Ç–µ—Å—Ç–æ–≤ –Ω–∞ –≥—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏
‚îú‚îÄ‚îÄ test_serialization.py    # Round-trip —Ç–µ—Å—Ç—ã
‚îî‚îÄ‚îÄ fixtures/
    ‚îî‚îÄ‚îÄ corpus/              # –¢–µ—Å—Ç–æ–≤—ã–π –∫–æ—Ä–ø—É—Å —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        ‚îú‚îÄ‚îÄ code_heavy/      # –î–æ–∫—É–º–µ–Ω—Ç—ã —Å –ø—Ä–µ–æ–±–ª–∞–¥–∞–Ω–∏–µ–º –∫–æ–¥–∞
        ‚îú‚îÄ‚îÄ structured/      # –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        ‚îú‚îÄ‚îÄ mixed/           # –°–º–µ—à–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        ‚îú‚îÄ‚îÄ simple/          # –ü—Ä–æ—Å—Ç—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
        ‚îî‚îÄ‚îÄ edge_cases/      # –ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏
```

## –¢–µ—Å—Ç–æ–≤—ã–π –∫–æ—Ä–ø—É—Å

–î–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–¥–∏–∑–∞–π–Ω–∞ —Å–æ–∑–¥–∞—ë—Ç—Å—è –∫–æ—Ä–ø—É—Å –∏–∑ 15+ —Ä–µ–∞–ª—å–Ω—ã—Ö markdown –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –î–æ–∫—É–º–µ–Ω—Ç—ã | –ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ |
|-----------|-----------|------------|
| code_heavy | python_tutorial.md, api_reference.md, code_snippets.md | –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ CodeAwareStrategy |
| structured | user_guide.md, architecture_doc.md, faq.md | –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ StructuralStrategy |
| mixed | readme.md, changelog.md, contributing.md | –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–º–µ—à–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ |
| simple | notes.md, todo.md, blog_post.md | –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ FallbackStrategy |
| edge_cases | nested_code_blocks.md, large_tables.md, mixed_line_endings.md, unicode_heavy.md | –ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏ |

## Baseline Comparison

–ü–µ—Ä–µ–¥ —Ä–µ–¥–∏–∑–∞–π–Ω–æ–º —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è baseline —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:

```python
# scripts/save_baseline.py
def save_baseline(corpus_dir: Path, output_file: Path):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å baseline —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤—Å–µ—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–ø—É—Å–∞."""
    chunker = MarkdownChunker()
    results = {}
    
    for doc_path in corpus_dir.rglob("*.md"):
        content = doc_path.read_text()
        result = chunker.chunk(content)
        results[str(doc_path.relative_to(corpus_dir))] = {
            'chunk_count': len(result.chunks),
            'strategy_used': result.strategy_used,
            'chunks': [c.to_dict() for c in result.chunks]
        }
    
    output_file.write_text(json.dumps(results, indent=2))
```

## Rollback Criteria

| –ú–µ—Ç—Ä–∏–∫–∞ | –ü–æ—Ä–æ–≥ | –î–µ–π—Å—Ç–≤–∏–µ |
|---------|-------|----------|
| Chunk count difference | >5% | Review required |
| Content loss | >1% | Rollback |
| Property test failures | Any | Rollback |
| Table integrity errors | Any | Rollback |
| Fence balance errors | >1% increase | Review required |

## Property-Based —Ç–µ—Å—Ç—ã (test_properties.py)

### –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ (MUST HAVE)

```python
"""
Property-based —Ç–µ—Å—Ç—ã –¥–ª—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –¥–æ–º–µ–Ω–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤.

–ò—Å–ø–æ–ª—å–∑—É–µ–º Hypothesis –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
"""

from hypothesis import given, strategies as st, settings
from markdown_chunker import MarkdownChunker, ChunkConfig


# –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –≤–∞–ª–∏–¥–Ω–æ–≥–æ markdown
markdown_text = st.text(
    alphabet=st.characters(whitelist_categories=('L', 'N', 'P', 'Z')),
    min_size=1,
    max_size=10000
).filter(lambda x: x.strip())


class TestCriticalProperties:
    """–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–≤–æ–π—Å—Ç–≤–∞ —Å–∏—Å—Ç–µ–º—ã."""
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_prop1_no_content_loss(self, md_text: str):
        """
        PROP-1: No Content Loss
        
        ‚àÄ doc ‚àà ValidMarkdown:
          concat(chunks) - overlaps ‚â° doc
        """
        chunker = MarkdownChunker()
        result = chunker.chunk(md_text, include_analysis=True)
        
        # –°–æ–±—Ä–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —á–∞–Ω–∫–æ–≤ (–±–µ–∑ overlap)
        reconstructed = ""
        for i, chunk in enumerate(result.chunks):
            if i == 0:
                reconstructed += chunk.content
            else:
                overlap_size = chunk.metadata.get("overlap_size", 0)
                reconstructed += chunk.content[overlap_size:]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å whitespace –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        original_normalized = ' '.join(md_text.split())
        reconstructed_normalized = ' '.join(reconstructed.split())
        
        assert original_normalized == reconstructed_normalized
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_prop2_size_bounds(self, md_text: str):
        """
        PROP-2: Chunk Size Bounds
        
        ‚àÄ chunk ‚àà Chunks:
          len(chunk.content) ‚â§ max_chunk_size 
          ‚à® chunk.metadata["allow_oversize"] = True
        """
        config = ChunkConfig(max_chunk_size=1000)
        chunker = MarkdownChunker(config)
        result = chunker.chunk(md_text, include_analysis=True)
        
        for chunk in result.chunks:
            assert (
                len(chunk.content) <= config.max_chunk_size or
                chunk.metadata.get("allow_oversize", False)
            )
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_prop3_monotonic_ordering(self, md_text: str):
        """
        PROP-3: Monotonic Ordering
        
        ‚àÄ i < j: chunks[i].start_line ‚â§ chunks[j].start_line
        """
        chunker = MarkdownChunker()
        result = chunker.chunk(md_text, include_analysis=True)
        
        for i in range(len(result.chunks) - 1):
            assert result.chunks[i].start_line <= result.chunks[i + 1].start_line
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_prop4_no_empty_chunks(self, md_text: str):
        """
        PROP-4: No Empty Chunks
        
        ‚àÄ chunk ‚àà Chunks: chunk.content.strip() ‚â† ""
        """
        chunker = MarkdownChunker()
        result = chunker.chunk(md_text, include_analysis=True)
        
        for chunk in result.chunks:
            assert chunk.content.strip() != ""
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_prop5_valid_line_numbers(self, md_text: str):
        """
        PROP-5: Valid Line Numbers
        
        ‚àÄ chunk ‚àà Chunks:
          chunk.start_line ‚â• 1 ‚àß chunk.end_line ‚â• chunk.start_line
        """
        chunker = MarkdownChunker()
        result = chunker.chunk(md_text, include_analysis=True)
        
        for chunk in result.chunks:
            assert chunk.start_line >= 1
            assert chunk.end_line >= chunk.start_line
```

### –í–∞–∂–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ (SHOULD HAVE)

```python
class TestImportantProperties:
    """–í–∞–∂–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ —Å–∏—Å—Ç–µ–º—ã."""
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_prop9_idempotence(self, md_text: str):
        """
        PROP-9: Idempotence
        
        ‚àÄ doc ‚àà ValidMarkdown:
          chunk(doc) ‚â° chunk(doc)  (–ø–æ–≤—Ç–æ—Ä–Ω—ã–π –≤—ã–∑–æ–≤ –¥–∞—ë—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)
        """
        chunker = MarkdownChunker()
        
        result1 = chunker.chunk(md_text)
        result2 = chunker.chunk(md_text)
        
        assert len(result1.chunks) == len(result2.chunks)
        for c1, c2 in zip(result1.chunks, result2.chunks):
            assert c1.content == c2.content
            assert c1.start_line == c2.start_line
            assert c1.end_line == c2.end_line


class TestImportantPropertiesOther:
    """–í–∞–∂–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞ —Å–∏—Å—Ç–µ–º—ã."""
    
    @given(md_text=st.text(min_size=10).filter(lambda x: '```' in x))
    @settings(max_examples=50)
    def test_prop6_code_block_integrity(self, md_text: str):
        """
        PROP-6: Code Block Integrity
        
        ‚àÄ code_block ‚àà doc.code_blocks:
          ‚àÉ! chunk ‚àà Chunks: code_block ‚äÜ chunk.content
        """
        # –î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π code block
        md_with_code = f"Text before\n\n```python\nprint('hello')\n```\n\nText after"
        
        chunker = MarkdownChunker()
        result = chunker.chunk(md_with_code, include_analysis=True)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ code block –Ω–µ —Ä–∞–∑–±–∏—Ç
        code_block = "```python\nprint('hello')\n```"
        found_in_chunks = sum(
            1 for chunk in result.chunks 
            if code_block in chunk.content
        )
        
        assert found_in_chunks == 1, "Code block –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ–º —á–∞–Ω–∫–µ"
    
    @given(md_text=st.text(min_size=10))
    @settings(max_examples=50)
    def test_prop7_table_integrity(self, md_text: str):
        """
        PROP-7: Table Integrity
        
        ‚àÄ table ‚àà doc.tables:
          ‚àÉ! chunk ‚àà Chunks: table ‚äÜ chunk.content
        """
        # –î–æ–±–∞–≤–∏—Ç—å –≤–∞–ª–∏–¥–Ω—É—é —Ç–∞–±–ª–∏—Ü—É
        md_with_table = """Text before

| Col1 | Col2 |
|------|------|
| A    | B    |
| C    | D    |

Text after"""
        
        chunker = MarkdownChunker()
        result = chunker.chunk(md_with_table, include_analysis=True)
        
        # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ —Ä–∞–∑–±–∏—Ç–∞
        table_header = "| Col1 | Col2 |"
        found_in_chunks = sum(
            1 for chunk in result.chunks 
            if table_header in chunk.content
        )
        
        assert found_in_chunks == 1, "–¢–∞–±–ª–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –≤ —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ–º —á–∞–Ω–∫–µ"
    
    def test_prop8_serialization_roundtrip(self):
        """
        PROP-8: Serialization Round-Trip
        
        ‚àÄ result ‚àà ChunkingResult:
          ChunkingResult.from_dict(result.to_dict()) ‚â° result
        """
        from markdown_chunker import ChunkingResult
        
        chunker = MarkdownChunker()
        original = chunker.chunk("# Test\n\nContent", include_analysis=True)
        
        # Round-trip
        as_dict = original.to_dict()
        restored = ChunkingResult.from_dict(as_dict)
        
        assert len(restored.chunks) == len(original.chunks)
        assert restored.strategy_used == original.strategy_used
        for orig, rest in zip(original.chunks, restored.chunks):
            assert orig.content == rest.content
            assert orig.start_line == rest.start_line
            assert orig.end_line == rest.end_line
```

## –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç (test_integration.py)

```python
"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline.
"""

import pytest
from pathlib import Path
from markdown_chunker import MarkdownChunker, ChunkConfig


class TestFullPipeline:
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ pipeline –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö."""
    
    @pytest.fixture
    def sample_docs(self):
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã."""
        docs_dir = Path(__file__).parent / "fixtures" / "sample_docs"
        return {
            "code_heavy": (docs_dir / "code_heavy.md").read_text(),
            "structured": (docs_dir / "structured.md").read_text(),
            "mixed": (docs_dir / "mixed.md").read_text(),
            "simple": (docs_dir / "simple.md").read_text(),
        }
    
    def test_full_pipeline_all_docs(self, sample_docs):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å pipeline –Ω–∞ –≤—Å–µ—Ö —Ç–∏–ø–∞—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤."""
        chunker = MarkdownChunker()
        
        for doc_type, content in sample_docs.items():
            result = chunker.chunk(content, include_analysis=True)
            
            # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
            assert result.success, f"Failed for {doc_type}"
            assert len(result.chunks) > 0, f"No chunks for {doc_type}"
            assert result.strategy_used in ["code_aware", "structural", "fallback"]
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ–º–µ–Ω–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞
            self._verify_properties(result, content)
    
    def _verify_properties(self, result, original_content):
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≤—Å–µ –¥–æ–º–µ–Ω–Ω—ã–µ —Å–≤–æ–π—Å—Ç–≤–∞."""
        # PROP-1: No content loss (—É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞)
        total_content = sum(len(c.content) for c in result.chunks)
        assert total_content >= len(original_content) * 0.95
        
        # PROP-2: Size bounds
        for chunk in result.chunks:
            assert (
                chunk.size <= 4096 or 
                chunk.metadata.get("allow_oversize", False)
            )
        
        # PROP-3: Monotonic ordering
        for i in range(len(result.chunks) - 1):
            assert result.chunks[i].start_line <= result.chunks[i + 1].start_line
        
        # PROP-4: No empty chunks
        for chunk in result.chunks:
            assert chunk.content.strip()
        
        # PROP-5: Valid line numbers
        for chunk in result.chunks:
            assert chunk.start_line >= 1
            assert chunk.end_line >= chunk.start_line
```

## –¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ (test_edge_cases.py)

```python
"""
–¢–µ—Å—Ç—ã –≥—Ä–∞–Ω–∏—á–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤.

–ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä ‚Äî —Ç–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ edge cases.
"""

import pytest
from markdown_chunker import MarkdownChunker, ChunkConfig


class TestEdgeCases:
    """–ì—Ä–∞–Ω–∏—á–Ω—ã–µ —Å–ª—É—á–∞–∏."""
    
    def test_empty_input(self):
        """–ü—É—Å—Ç–æ–π –≤—Ö–æ–¥."""
        chunker = MarkdownChunker()
        result = chunker.chunk("", include_analysis=True)
        assert len(result.chunks) == 0
    
    def test_whitespace_only(self):
        """–¢–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã."""
        chunker = MarkdownChunker()
        result = chunker.chunk("   \n\n   ", include_analysis=True)
        assert len(result.chunks) == 0
    
    def test_single_character(self):
        """–û–¥–∏–Ω —Å–∏–º–≤–æ–ª."""
        chunker = MarkdownChunker()
        result = chunker.chunk("X", include_analysis=True)
        assert len(result.chunks) == 1
        assert result.chunks[0].content == "X"
    
    def test_very_long_line(self):
        """–û—á–µ–Ω—å –¥–ª–∏–Ω–Ω–∞—è —Å—Ç—Ä–æ–∫–∞ –±–µ–∑ –ø–µ—Ä–µ–Ω–æ—Å–æ–≤."""
        chunker = MarkdownChunker(ChunkConfig(max_chunk_size=100))
        long_line = "word " * 100  # 500 —Å–∏–º–≤–æ–ª–æ–≤
        result = chunker.chunk(long_line, include_analysis=True)
        
        # –î–æ–ª–∂–µ–Ω —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤
        assert len(result.chunks) > 1
    
    def test_oversized_code_block(self):
        """Code block –±–æ–ª—å—à–µ max_chunk_size."""
        chunker = MarkdownChunker(ChunkConfig(max_chunk_size=100))
        large_code = "```python\n" + "x = 1\n" * 50 + "```"
        result = chunker.chunk(large_code, include_analysis=True)
        
        # Code block –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑–±–∏—Ç
        assert any("```python" in c.content and "```" in c.content 
                   for c in result.chunks)
    
    def test_nested_code_blocks(self):
        """–í–ª–æ–∂–µ–Ω–Ω—ã–µ code blocks (markdown –≤ markdown)."""
        md = '''
````markdown
```python
print("hello")
```
````
'''
        chunker = MarkdownChunker()
        result = chunker.chunk(md, include_analysis=True)
        
        # –í–Ω–µ—à–Ω–∏–π –±–ª–æ–∫ –Ω–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–∞–∑–±–∏—Ç
        assert len(result.chunks) >= 1
    
    def test_unicode_content(self):
        """Unicode –∫–æ–Ω—Ç–µ–Ω—Ç."""
        md = "# –ó–∞–≥–æ–ª–æ–≤–æ–∫ üéâ\n\n–¢–µ–∫—Å—Ç —Å —ç–º–æ–¥–∑–∏ üëç –∏ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π"
        chunker = MarkdownChunker()
        result = chunker.chunk(md, include_analysis=True)
        
        assert len(result.chunks) >= 1
        assert "üéâ" in result.chunks[0].content
    
    def test_mixed_line_endings(self):
        """–°–º–µ—à–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫."""
        md = "Line1\r\nLine2\nLine3\rLine4"
        chunker = MarkdownChunker()
        result = chunker.chunk(md, include_analysis=True)
        
        assert len(result.chunks) >= 1
    
    def test_deeply_nested_headers(self):
        """–ì–ª—É–±–æ–∫–æ –≤–ª–æ–∂–µ–Ω–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏."""
        md = "\n".join([f"{'#' * i} Header {i}" for i in range(1, 7)])
        chunker = MarkdownChunker()
        result = chunker.chunk(md, include_analysis=True)
        
        assert len(result.chunks) >= 1
    
    def test_table_at_document_end(self):
        """–¢–∞–±–ª–∏—Ü–∞ –≤ –∫–æ–Ω—Ü–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞."""
        md = """# Title

| A | B |
|---|---|
| 1 | 2 |"""
        chunker = MarkdownChunker()
        result = chunker.chunk(md, include_analysis=True)
        
        # –¢–∞–±–ª–∏—Ü–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Ü–µ–ª–æ–π
        assert any("| A | B |" in c.content for c in result.chunks)
```

## –£–¥–∞–ª—è–µ–º—ã–µ —Ç–µ—Å—Ç—ã

### –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è

1. **–¢–µ—Å—Ç—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏** ‚Äî —Ç–µ—Å—Ç–∏—Ä—É—é—Ç –ö–ê–ö —Ä–∞–±–æ—Ç–∞–µ—Ç, –∞ –Ω–µ –ß–¢–û
   - `test_strategy_selector.py` ‚Äî –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –ª–æ–≥–∏–∫–∞ –≤—ã–±–æ—Ä–∞
   - `test_fallback_manager.py` ‚Äî –º–µ—Ö–∞–Ω–∏–∑–º fallback
   - `test_orchestrator.py` ‚Äî –æ—Ä–∫–µ—Å—Ç—Ä–∞—Ü–∏—è

2. **–î—É–±–ª–∏—Ä—É—é—â–∏–µ —Ç–µ—Å—Ç—ã** ‚Äî –æ–¥–Ω–æ –∏ —Ç–æ –∂–µ –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
   - `test_overlap_properties.py` + `test_overlap_properties_redesign.py`
   - `test_full_pipeline.py` + `test_end_to_end.py` + `test_full_api_flow.py`

3. **–¢–µ—Å—Ç—ã –¥–ª—è –±–∞–≥—Ñ–∏–∫—Å–æ–≤** ‚Äî —Ñ–∏–∫—Å–∏—Ä—É—é—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é
   - `test_critical_fixes.py`
   - `test_phase2_properties.py`
   - `test_overlap_duplication.py`

4. **–¢–µ—Å—Ç—ã –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π** ‚Äî –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –æ–¥–∏–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–æ–≤–∞–Ω–Ω—ã–π
   - `test_code_strategy_properties.py`
   - `test_list_strategy_properties.py`
   - `test_mixed_strategy_properties.py`
   - `test_structural_strategy_properties.py`
   - `test_table_strategy_properties.py`
   - `test_sentences_strategy_properties.py`

### –°–æ—Ö—Ä–∞–Ω—è–µ–º—ã–µ —Ç–µ—Å—Ç—ã

- Property-based —Ç–µ—Å—Ç—ã –¥–ª—è –¥–æ–º–µ–Ω–Ω—ã—Ö —Å–≤–æ–π—Å—Ç–≤ (–ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å)
- –û–¥–∏–Ω –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç
- –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä edge cases
- Round-trip —Ç–µ—Å—Ç—ã –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏

## –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ property-based —Ç–µ—Å—Ç—ã (Design Fixes)

```python
# tests/test_design_fixes.py
"""
Property-based —Ç–µ—Å—Ç—ã –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–∏–∑–∞–π–Ω–∞.
"""

class TestDesignFixesProperties:
    """Property-based —Ç–µ—Å—Ç—ã –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–∏–∑–∞–π–Ω–∞."""
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_line_ending_normalization(self, md_text: str):
        """
        Property: Line Ending Normalization
        
        ‚àÄ doc: –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ—Ç \r –≤ –∫–æ–Ω—Ç–µ–Ω—Ç–µ —á–∞–Ω–∫–æ–≤
        **Validates: Requirements 6.1, 6.2, 6.3**
        """
        md_with_crlf = md_text.replace('\n', '\r\n')
        
        chunker = MarkdownChunker()
        result = chunker.chunk(md_with_crlf)
        
        for chunk in result.chunks:
            assert '\r' not in chunk.content
    
    @given(md_text=markdown_text)
    @settings(max_examples=100)
    def test_oversize_metadata_correctness(self, md_text: str):
        """
        Property: Oversize Metadata Correctness
        
        ‚àÄ chunk —Å size > max_chunk_size: 
          allow_oversize=True AND oversize_reason ‚àà {valid_reasons}
        **Validates: Requirements 5.1, 5.3**
        """
        config = ChunkConfig(max_chunk_size=500)
        chunker = MarkdownChunker(config)
        result = chunker.chunk(md_text)
        
        VALID_REASONS = {'code_block_integrity', 'table_integrity', 'section_integrity'}
        
        for chunk in result.chunks:
            if chunk.size > config.max_chunk_size:
                assert chunk.metadata.get("allow_oversize") == True
                assert chunk.metadata.get("oversize_reason") in VALID_REASONS
    
    def test_code_fence_balance(self):
        """
        Property: Code Fence Balance
        
        ‚àÄ chunk: fence_count % 2 == 0 OR fence_balance_error=True
        **Validates: Requirements 3.1, 3.2**
        """
        md_with_code = "```python\nprint('hello')\n```\n\nText\n\n```js\nconsole.log('hi')\n```"
        
        chunker = MarkdownChunker(ChunkConfig(max_chunk_size=50))
        result = chunker.chunk(md_with_code)
        
        for chunk in result.chunks:
            fence_count = chunk.content.count('```')
            assert fence_count % 2 == 0 or chunk.metadata.get("fence_balance_error")
    
    def test_table_integrity(self):
        """
        Property: Table Integrity
        
        ‚àÄ table: table —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –≤ —Ä–æ–≤–Ω–æ –æ–¥–Ω–æ–º —á–∞–Ω–∫–µ
        **Validates: Requirements 4.1, 4.2, 4.3**
        """
        md_with_table = """# Title

| Col1 | Col2 | Col3 |
|------|------|------|
| A    | B    | C    |
| D    | E    | F    |

Some text after table."""
        
        chunker = MarkdownChunker()
        result = chunker.chunk(md_with_table)
        
        table_header = "| Col1 | Col2 | Col3 |"
        containing_chunks = [c for c in result.chunks if table_header in c.content]
        
        assert len(containing_chunks) == 1
    
    def test_overlap_integrity(self):
        """
        Property: Overlap Integrity
        
        ‚àÄ chunk —Å overlap: previous_content —è–≤–ª—è–µ—Ç—Å—è —Å—É—Ñ—Ñ–∏–∫—Å–æ–º –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —á–∞–Ω–∫–∞
        **Validates: Requirements 2.1, 2.2, 2.3**
        """
        md = "A" * 1000 + "\n\n" + "B" * 1000
        
        chunker = MarkdownChunker(ChunkConfig(max_chunk_size=500, overlap_size=100))
        result = chunker.chunk(md)
        
        for i in range(1, len(result.chunks)):
            chunk = result.chunks[i]
            prev_chunk = result.chunks[i - 1]
            
            previous_content = chunk.metadata.get("previous_content", "")
            if previous_content:
                assert prev_chunk.content.endswith(previous_content)
```

## –ú–∏–≥—Ä–∞—Ü–∏—è —Ç–µ—Å—Ç–æ–≤

### –§–∞–∑–∞ 1: –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö —Ç–µ—Å—Ç–æ–≤

1. –ù–∞–ø–∏—Å–∞—Ç—å 10 property-based —Ç–µ—Å—Ç–æ–≤ (PROP-1 —á–µ—Ä–µ–∑ PROP-10)
2. –ù–∞–ø–∏—Å–∞—Ç—å 6 property-based —Ç–µ—Å—Ç–æ–≤ –¥–ª—è design fixes
3. –ù–∞–ø–∏—Å–∞—Ç—å 1 –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç
4. –ù–∞–ø–∏—Å–∞—Ç—å ~10 edge case —Ç–µ—Å—Ç–æ–≤
5. –£–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ —Ç–µ–∫—É—â–∏–π –∫–æ–¥ –ø—Ä–æ—Ö–æ–¥–∏—Ç –Ω–æ–≤—ã–µ —Ç–µ—Å—Ç—ã

### –§–∞–∑–∞ 2: –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –∑–∞–ø—É—Å–∫

1. –ó–∞–ø—É—Å–∫–∞—Ç—å –∏ —Å—Ç–∞—Ä—ã–µ, –∏ –Ω–æ–≤—ã–µ —Ç–µ—Å—Ç—ã
2. –°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
3. –§–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è

### –§–∞–∑–∞ 3: –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Ç–µ—Å—Ç–æ–≤

1. –ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ —Ä–µ–¥–∏–∑–∞–π–Ω–∞ —É–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—ã–µ —Ç–µ—Å—Ç—ã
2. –û—Å—Ç–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ
3. –û–±–Ω–æ–≤–∏—Ç—å CI/CD
